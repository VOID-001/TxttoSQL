project/
|-- main.py
|-- routes/
|   |-- db_connection.py
|   |-- schema_management.py
|   |-- api_key.py
|   |-- sql_execution.py
|-- utils/
|   |-- pgvector_client.py
|   |-- chatgpt_client.py
|   |-- logger.py
|-- schema/                # New directory for storing CSV files

### Updated Scripts

#### **`routes/db_connection.py`**
Manages the database connection dynamically via FastAPI.

```python
from fastapi import APIRouter, HTTPException
from utils.pgvector_client import initialize_pgvector_client

db_connection_router = APIRouter()

@db_connection_router.post("/connect-db/")
async def connect_db(connection_url: str):
    """Set the database connection URL dynamically."""
    try:
        initialize_pgvector_client(connection_url)
        return {"detail": "Connected to database successfully."}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Connection failed: {str(e)}")
```

---

#### **`routes/schema_management.py`**
Handles schema metadata extraction and uploads schema for buffer logic.

```python
from fastapi import APIRouter, HTTPException, UploadFile, File
import csv
import io
from utils.pgvector_client import get_schema_metadata

schema_management_router = APIRouter()

BUFFER = {}

@schema_management_router.get("/get-schema-metadata/")
async def get_schema_metadata_csv():
    """Fetch schema metadata and save it as a CSV file."""
    try:
        schema_data = get_schema_metadata()
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["Table", "Column", "Data Type"])
        writer.writerows(schema_data)
        output.seek(0)
        return {"schema_csv": output.getvalue()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error fetching schema metadata: {str(e)}")

@schema_management_router.post("/upload-schema/")
async def upload_schema(file: UploadFile = File(...)):
    """Upload schema file and process into buffer."""
    global BUFFER
    try:
        contents = await file.read()
        buffer_data = io.StringIO(contents.decode())
        reader = csv.DictReader(buffer_data)
        for row in reader:
            key = row["Table"]
            if key not in BUFFER:
                BUFFER[key] = {"Columns": []}
            BUFFER[key]["Columns"].append(f"{row['Column']} ({row['Data Type']})")
        return {"detail": "Schema successfully uploaded and stored in buffer.", "buffer": BUFFER}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Error processing schema file: {str(e)}")

@schema_management_router.get("/print-buffer/")
async def print_buffer():
    """Print the current buffer."""
    return {"buffer": BUFFER}
```

---

#### **`routes/api_key.py`**
Handles schema validation and query preparation.

```python
from fastapi import APIRouter, HTTPException
from utils.chatgpt_client import generate_sql_from_question
from routes.schema_management import BUFFER

api_key_router = APIRouter()

@api_key_router.post("/validate-schema/")
async def validate_schema(key: str):
    """Validate if the key exists in the buffer."""
    if key in BUFFER:
        return {"detail": "Key is present in buffer.", "schema": BUFFER[key]}
    else:
        raise HTTPException(status_code=404, detail="Key not found in buffer.")

@api_key_router.post("/generate-query/")
async def generate_query_from_key(key: str, question: str):
    """Generate a SQL query based on schema and question."""
    if key not in BUFFER:
        raise HTTPException(status_code=404, detail="Key not found in buffer.")

    schema_context = f"Key: {key}\nTables and Columns:\n"
    for table, columns in BUFFER[key].items():
        schema_context += f"{table}: {', '.join(columns)}\n"

    sql_query = generate_sql_from_question(f"Schema:\n{schema_context}\nQuestion: {question}")
    return {"sql_query": sql_query}
```

---

#### **`routes/sql_execution.py`**
Handles SQL execution on the database.

```python
from fastapi import APIRouter, HTTPException
from utils.pgvector_client import execute_sql_query

sql_execution_router = APIRouter()

@sql_execution_router.post("/execute-query/")
async def execute_query(sql_query: str):
    """Execute an input SQL query and return results."""
    try:
        results = execute_sql_query(sql_query)
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Error executing query: {str(e)}")
```

---

#### **`utils/pgvector_client.py`**
Database connection and schema metadata utility.

```python
import psycopg2

pgvector_client = None

def initialize_pgvector_client(database_url):
    global pgvector_client
    pgvector_client = psycopg2.connect(database_url)

def get_schema_metadata():
    """Fetch schema metadata from the database."""
    query = """
    SELECT table_name, column_name, data_type
    FROM information_schema.columns
    WHERE table_schema = 'public';
    """
    cursor = pgvector_client.cursor()
    cursor.execute(query)
    return cursor.fetchall()

def execute_sql_query(query):
    """Execute a SQL query on the database."""
    cursor = pgvector_client.cursor()
    cursor.execute(query)
    return cursor.fetchall()
```

---

#### **`utils/chatgpt_client.py`**
Generates SQL query based on schema and question.

```python
import openai

def generate_sql_from_question(question: str):
    """Generate SQL query using OpenAI GPT."""
    if not openai.api_key:
        raise ValueError("OpenAI API key is not set.")

    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=f"Translate the following question into an SQL query:\n{question}",
        max_tokens=150
    )
    return response.choices[0].text.strip()
```

---

#### **`main.py`**
Entry point for the FastAPI application.

```python
from fastapi import FastAPI
from routes.db_connection import db_connection_router
from routes.schema_management import schema_management_router
from routes.sql_execution import sql_execution_router
from routes.api_key import api_key_router

app = FastAPI()

# Include routers
app.include_router(db_connection_router, prefix="/api")
app.include_router(schema_management_router, prefix="/api")
app.include_router(sql_execution_router, prefix="/api")
app.include_router(api_key_router, prefix="/api")

@app.get("/")
def read_root():
    return {"message": "FastAPI with dynamic DB schema handling and buffer logic is running!"}
```

This implementation provides a **buffer-based schema handling system** that supports all the requested endpoints. Let me know if you'd like any refinements or additional functionality!